import boto3
from botocore.exceptions import ClientError
import json
from datetime import datetime
from pg8000.native import Connection, identifier
import sys
import pyarrow.parquet as pa
import pandas as pd
import io


sys.path.append("src/src_ingestion")


# def entry(client):
#     """will only be used once to create the initial secret that will store the totesys DB credentials"""
#     if "SecretsManager" in str(type(client)):
#         secret_identifier = "de_2024_12_02"
#         get_username = input("Please enter your username: ")
#         get_password = input("Please enter your password:")
#         get_host = input("Please enter your host: ")
#         get_database = input("Please enter your database: ")
#         get_port = input("Please enter your port: ")
#         secret_value = {
#             "username": get_username,
#             "password": get_password,
#             "host": get_host,
#             "database": get_database,
#             "port": get_port,
#         }
#         secret_string = json.dumps(secret_value)
#         try:
#             client.create_secret(Name=secret_identifier, SecretString=secret_string)
#             print("Secret saved.")
#         except client.exceptions.ResourceExistsException as e:
#             print("Secret already exists!")
#         except Exception as err:
#             print({"ERROR": err, "message": "Fail to connect to aws secret manager!"})
#     else:
#         print("invalid client type used for secret manager! plz contact developer!")

def retrieval(client, secret_identifier='de_2024_12_02_dw'):
    """return the credentials to the totesys db in a dictionary"""
    if "SecretsManager" in str(type(client)):
        try:
            response = client.get_secret_value(SecretId=secret_identifier)
            res_str = response["SecretString"]
            res_dict = json.loads(res_str)
            return res_dict
        except client.exceptions.ResourceNotFoundException as err:
            print(err)
        except Exception as err:
            print({"ERROR": err, "massage": "Fail to connect to aws secret manager!"})
    else:
        print("invalid client type used for secret manager! plz contact developer!")


def connect_to_db(secret_identifier='de_2024_12_02_dw'):
    """return conn to totesys db"""
    client = get_secrets_manager_client()
    credentials = retrieval(client, secret_identifier=secret_identifier)

    # if not credentials:
    #     entry(client)
    #     credentials = retrieval(client)

    return Connection(
        user=credentials["username"],
        password=credentials["password"],
        database=credentials["database"],
        host=credentials["host"],
    )


def close_db_connection(conn):
    """close db"""
    conn.close()


def get_s3_client():
    """return a client to connect to s3"""
    try:
        client = boto3.client("s3", region_name="eu-west-2")
        return client
    except ClientError:
        raise ClientError(
            {
                "Error": {
                    "Code": "FailedToConnect",
                    "Message": "failed to connect to s3",
                }
            },
            "GetS3Client",
        )


def get_secrets_manager_client():
    """return a client to connect to secret manager"""
    try:
        client = boto3.client("secretsmanager", region_name="eu-west-2")
        return client
    except ClientError:
        raise ClientError(
            {
                "Error": {
                    "Code": "FailedToConnect",
                    "Message": "failed to connect to secret manager",
                }
            },
            "GetSecretsManagerClient",
        )


def pd_read_s3_parquet(key, bucket, s3_client):
    obj = s3_client.get_object(Bucket=bucket, Key=key)
    df = pd.read_parquet(io.BytesIO(obj['Body'].read()), engine='pyarrow')
    return df

# Read multiple parquets from a folder on S3 generated by spark
# def pd_read_s3_multiple_parquets(filepath, bucket, **args):
#     s3_client = get_s3_client('s3')
#     s3 = boto3.resource('s3')
#     if not filepath.endswith('/'):
#         filepath = filepath + '/'  # Add '/' to the end
              
#     s3_keys = [item.key for item in s3.Bucket(bucket).objects.filter(Prefix=filepath)
#                if item.key.endswith('.parquet')]
    
#     if not s3_keys:
#         print('No parquet found in', bucket, filepath)
    
#         # for p in s3_keys: 
#         #     print(p)
#     dfs = [pd_read_s3_parquet(key, bucket=bucket, s3_client=s3_client, **args) 
#            for key in s3_keys]
#     return dfs      


def load_tables_to_dw(df, table_name):
    conn = connect_to_db()
    if table_name == 'fact_sales_order': 
        df.to_sql(table_name, con=conn, if_exists='append',index=False)
    else:
        df.to_sql(table_name, con=conn, if_exists='replace',index=False)
    
    
    

